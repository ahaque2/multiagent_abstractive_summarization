{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e04be93d-110f-4be5-9e8e-a4380abb1481",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ahaque2/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "from multiagent_summariser import get_multiagent_summary\n",
    "from writer_critic import get_writer_critic_summary\n",
    "import json\n",
    "import logging \n",
    "from openai import OpenAI\n",
    "from typing import List\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ded4b9f-956c-4116-a8d5-6627ab474651",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "os.environ[\"LAS_API_TOKEN\"] = \"a4adfef6de531c1c258c9eda6f9be5c7a5701e365c32babe72273f63214811df\"\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"LAS_API_TOKEN\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8025825-2653-4d54-a290-2a92572264bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from openai import OpenAI\n",
    "\n",
    "# def get_chatpgt_summary(prompt, news):\n",
    "\n",
    "#     # prompt = prompt.replace('{Questions}', qa)\n",
    "#     chat_completion = client.chat.completions.create(\n",
    "#         messages=[\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": prompt + news\n",
    "#             }\n",
    "#         ],\n",
    "#         model=\"gpt-4o\",\n",
    "#     )\n",
    "#     return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50a2aef3-714d-41d1-af1d-14d50eefdb66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get_chatpgt_summary(\"What is the capital of Paris?\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5158a242-8ef1-4cf3-b3e4-982a552430c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b0ea4d1-f186-4168-b844-b4515267216f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PromptTunedAgent:\n",
    "    \"\"\"\n",
    "    This class enables a series of iterative conversations to take place between the user \n",
    "    and the LLM. This can be used to provide few shot tuning to the LLM\n",
    "    \"\"\"\n",
    "    def __init__(self, prompt_setup: List[str]) -> None:\n",
    "        logging.basicConfig(filename=\"logs/.log\",\n",
    "                    filemode='w',\n",
    "                    format='%(message)s',\n",
    "                    level=logging.WARN)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.logger.setLevel(logging.WARNING)\n",
    "        self.client = OpenAI(\n",
    "            # This is the default and can be omitted\n",
    "            api_key=os.environ.get(\"LAS_API_TOKEN\")\n",
    "        )\n",
    "        self.model = \"gpt-4o\"\n",
    "        self.temperature=1.0\n",
    "        self.messages = [\n",
    "        ]\n",
    "\n",
    "        for message in prompt_setup:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=self.messages\n",
    "            )\n",
    "            self.messages.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content})\n",
    "        \n",
    "        self.logger.debug(json.dumps(self.messages, indent=2))\n",
    "\n",
    "    def chat(self, message: str, mute=False) -> str:\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=self.messages+[{\"role\": \"user\", \"content\": message}],\n",
    "            temperature=self.temperature\n",
    "        )\n",
    "        result = response.choices[0].message.content\n",
    "\n",
    "        self.logger.warning(result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a6f9b93-aff4-4064-ac7c-8ccaf9ede9d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First summary using t=1.2\n",
      "First summary using t=1.2\n",
      "First summary using t=1.2\n",
      "First summary using t=1.2\n",
      "Intermediate summary using t=1.0\n",
      "Intermediate summary using t=1.0\n",
      "Intermediate summary using t=1.0\n",
      "Intermediate summary using t=1.0\n",
      "Final summary using t=0\n",
      "Final summary using t=0\n",
      "Final summary using t=0\n",
      "Final summary using t=0\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "df = pd.read_csv(\"../data/conflicting_news_dataset.csv\")\n",
    "df = df.head(2)\n",
    "multi_agent_summary = []\n",
    "writer_critic_summary = []\n",
    "cluster = []\n",
    "num_sentences = 5\n",
    "# %%\n",
    "for cluster_id in set(df[\"cluster_id\"]):\n",
    "    clustered_articles = df[df[\"cluster_id\"]==cluster_id]\n",
    "    docs = clustered_articles[\"text\"]\n",
    "    personalisation = [\"Your summaries should be written from the perspertive a person with right leaning political tendancies\"]*2\n",
    "    personalisation += [\"Your summaries should be written from the perspertive a person with left leaning political tendancies\"]*2\n",
    "    multi_agent_summary.append(get_multiagent_summary(docs, personalisation, num_sentences=num_sentences))\n",
    "    articles = '\\n'.join(docs)\n",
    "    writer_critic_summary.append(get_writer_critic_summary(docs, num_sentences=num_sentences))\n",
    "    cluster.append(cluster_id)\n",
    "\n",
    "results_df = pd.DataFrame.from_dict({\"cluster\": cluster, \"multiagent_summary\": multi_agent_summary, \"writer_critic_summary\": writer_critic_summary})\n",
    "# results_df.to_csv(\"sample_conflicting_news_dataset_enriched.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63806b0d-3447-4023-a909-f32f61e4373b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>multiagent_summary</th>\n",
       "      <th>writer_critic_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A recent collection of news articles reveals t...</td>\n",
       "      <td>In a recent report by The New York Times, it w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster                                 multiagent_summary  \\\n",
       "0        1  A recent collection of news articles reveals t...   \n",
       "\n",
       "                               writer_critic_summary  \n",
       "0  In a recent report by The New York Times, it w...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dd93a0-b484-47ec-9b93-842da8e01155",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3a7812-e5aa-4f02-8025-0823549cbf6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_scads_venv",
   "language": "python",
   "name": "py3_scads_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
