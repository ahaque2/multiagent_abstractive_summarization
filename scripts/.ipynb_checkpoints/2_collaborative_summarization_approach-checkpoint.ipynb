{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9eb2a04-82aa-4912-889d-ff5103e9685f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81430f19-1be9-4ccb-bca0-2255b3d06cf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "os.environ[\"LAS_API_TOKEN\"] = \"a4adfef6de531c1c258c9eda6f9be5c7a5701e365c32babe72273f63214811df\"\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"LAS_API_TOKEN\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba9fb34e-2bd8-4030-9eb8-4eddb0c688b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from openai import OpenAI\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import copy \n",
    "\n",
    "class ComposableAgent:\n",
    "    \"\"\"\n",
    "    This class enables a series of iterative conversations to take place between the user \n",
    "    and a persistant LLM agent. \n",
    "    \"\"\"\n",
    "    def __init__(self, prompt_setup: List[str]) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            prompt_setup: A list of prompts used to give the agent their persona and any few shot\n",
    "            prompt examples etc\n",
    "        \"\"\"\n",
    "        # logging.basicConfig(filename=\"logs/.test\",\n",
    "        #             filemode='w',\n",
    "        #             format='%(message)s',\n",
    "        #             level=logging.WARN)\n",
    "        # self.logger = logging.getLogger(__name__)\n",
    "        # self.logger.setLevel(logging.WARNING)\n",
    "        \n",
    "        self.client = OpenAI(\n",
    "            api_key=os.environ.get(\"LAS_API_TOKEN\")\n",
    "        )\n",
    "        self.model = \"gpt-3.5-turbo\"\n",
    "        \n",
    "        self.messages = [\n",
    "        ]\n",
    "        for message in prompt_setup:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=self.messages\n",
    "            )\n",
    "            self.messages.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content})\n",
    "\n",
    "        # self.logger.debug(json.dumps(self.messages, indent=2))\n",
    "        self.count = 1\n",
    "        \n",
    "    def chat(self, message: str) -> str:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            message: A prompting string for the LLM\n",
    "        \"\"\"\n",
    "        if self.count<2:\n",
    "            # Use higher temperature for the first summaries to \n",
    "            # encourage diversity of summaries\n",
    "            temperature = 1.2\n",
    "        else:\n",
    "            # On all subsequent iterations use a low temperature to speed\n",
    "            # up the convergence\n",
    "            temperature = 0\n",
    "\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        while True:\n",
    "            try:\n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=self.model,\n",
    "                    messages=self.messages,\n",
    "                    temperature=temperature\n",
    "                )\n",
    "                break\n",
    "            except:\n",
    "                # if the OpenAI API throws an error wait befefore retrying \n",
    "                time.sleep(0.1)\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content})\n",
    "        result = response.choices[0].message.content\n",
    "        self.count += 1\n",
    "        \n",
    "        return result\n",
    "    \n",
    "\n",
    "def combine_reviews(reviews):\n",
    "    \n",
    "    rev = \"\"\n",
    "    for i, r in enumerate(reviews):\n",
    "        if(rev == \"\"):\n",
    "            rev = \"Review 1: \" + str(r)\n",
    "            \n",
    "        else:\n",
    "            rev = rev + \"\\n\\n========\\n\\nReview \" + str(i+1) + \": \" + r\n",
    "            \n",
    "    return rev\n",
    "\n",
    "def create_initial_prompts(topics, topic_df):\n",
    "    \n",
    "    prompt = open('../prompts/topic_prompts.txt', 'r').read()\n",
    "    prompts = []\n",
    "    for t in topics:\n",
    "        \n",
    "        prompts.append(prompt.replace('{topic}', t).replace('{description}', topic_df[topic_df['Topic'] == t]['Description'].values[0]))\n",
    "        \n",
    "    return prompts\n",
    "\n",
    "\n",
    "def get_intermediate_summaries(reviews, topics, topic_df):\n",
    "    \"\"\"\n",
    "    Returns the intermediate summaries generated by agents with a focus on one aspect (i.e., one summary for each aspect)\n",
    "    \"\"\"\n",
    "    \n",
    "    reviews_ = combine_reviews(reviews)\n",
    "    \n",
    "    FIRST_PROMPT = f\"Summarise the following reviews:\\n{reviews_}\"\n",
    "    \n",
    "    prompts = create_initial_prompts(topics, topic_df)\n",
    "    \n",
    "    agents = [ComposableAgent([x]) for x in prompts]\n",
    "    \n",
    "    iteration_results = []\n",
    "    agent_results = []\n",
    "    for top, agent in zip(topics, agents):\n",
    "        # print(\"Topic: \", top)\n",
    "        int_sum = agent.chat(FIRST_PROMPT)\n",
    "        \n",
    "        # print(\"summary: \", int_sum, \"\\n\\n\")\n",
    "        agent_results.append({top: int_sum})\n",
    "    iteration_results.append(agent_results)\n",
    "    \n",
    "    return iteration_results\n",
    "\n",
    "\n",
    "def synthesize_final_summary(reviews, intermediate_summaries):\n",
    "\n",
    "    final_prompt = open('../prompts/summary_synthesis_prompts_self_review.txt', 'r').read()\n",
    "    summary_prompt = \"\\n\\nReview 1: \" + reviews[0] + \"\\n\\n=======\\n\\nReview 2: \" + reviews[1] + \"\\n\\n=======\\n\\nThe conflicts between the two reviews are as follows:\\n\"\n",
    "    # print(iter_prompt)\n",
    "\n",
    "    for s in intermediate_summaries[0]:\n",
    "        top = list(s.keys())[0]\n",
    "        conflict = list(s.values())[0].replace('Summary:\\n', '')\n",
    "        summary_prompt += f\"\\n\\n{top}: {conflict}\"\n",
    "    # iter_prompt += \"\\n\\nProduce an updated summary which incorporates the best parts of the summaries from the other agents and preserves the best part of your current summary. In evaluating which parts of a summary are good you may consider the contents of the origonal article. The objective of these summaries is to capture all the important information from the origonal article in one sentence. Format the summary in a single paragraph. Don't give any explanation, just return the updated summary.\"\n",
    "    # final_prompt += summary_prompt\n",
    "    # agent_results.append({\"content\": agent.chat(iter_prompt)})\n",
    "    \n",
    "    summary_agents = ComposableAgent([final_prompt])\n",
    "    summary = summary_agents.chat(summary_prompt)\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f0d70fc-fbc5-49b0-bbca-1e959a546cab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# topics = ['quality of service', 'cleanliness of the place', 'value or worth for the money', 'quality of sleep', \n",
    "#           'details about the room such as bed, pillows, furnitures, walls, etc.', 'Business service (e.g., internet access)', 'check in and front desk services']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26fec3dc-eb37-4e4d-9da9-ebd6fbee1a67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topics = ['Service', 'Cleanliness', 'Value', 'Sleep Quality', 'Rooms', 'Business service (e.g., internet access)', 'Check in / front desk']\n",
    "topic_df = pd.read_csv('../data/topic_definitions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "805d31c8-e74b-4478-bea2-92985a9dcb64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/conflicted_reviews_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "febd6d92-4a12-46da-9ab3-978a0615f522",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['Unnamed: 0', 'rev_neg', 'rev_pos', 'attr_neg', 'attr_pos', 'cls',\n",
       "        'summary'],\n",
       "       dtype='object'),\n",
       " (12, 7))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns, df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "382d0e1d-f2c2-489b-aa32-3b0f41d3d150",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_summary = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    reviews = [row['rev_neg'], row['rev_pos']]\n",
    "    # print(reviews)\n",
    "    \n",
    "    intermediate_summaries = get_intermediate_summaries(reviews, topics, topic_df)\n",
    "    \n",
    "    summary = synthesize_final_summary(reviews, intermediate_summaries)\n",
    "    \n",
    "    final_summary.append(summary)\n",
    "    # print(summary)\n",
    "    # sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "aafff68c-3b64-4189-88a1-51e4606a1849",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['collaborative_summary'] = final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "901777e4-9296-4afb-88f1-e0e0c761b333",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('../results/news_summaries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399e3306-77a6-4d49-9c1f-aa439de5c83c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_scads_venv",
   "language": "python",
   "name": "py3_scads_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
